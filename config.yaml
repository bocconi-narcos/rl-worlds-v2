# configs/base_config.yaml

# --- Environment Configuration ---
environment:
  name: "ALE/Assault-v5" # Simple environment for testing (was "ALE/Assault-v5")
  
  # Image preprocessing parameters
  frame_stack_size: 4         # Number of frames to stack (1 = no stacking, 4 = stack 4 frames)
  image_height: 64            # Target height for image preprocessing
  image_width: 64             # Target width for image preprocessing
  

# --- Data Collection & Dataset Management ---
data_collection:
  num_episodes: 5
  max_steps_per_episode: 100
  random_action_percentage: 0.0 # Percentage of actions to be random (0.0 = no random actions)
  load_path: "assault_rep_4.pth"
  filename: "assault_rep_4.pth"
  validation_split: 0.2
  sequence_length: 6
  ppo_agent:
    load: false # Whether to load a pre-trained PPO agent
    n_envs: 10 # Number of parallel environments for PPO training (default: CPU count)
    action_repetition_k: 4
    learning_rate: 0.0003
    total_train_timesteps: 100 # Timesteps to train PPO before data collection (reduced for testing)
    n_steps: 32       # PPO n_steps parameter
    batch_size: 256      # PPO batch_size parameter
    n_epochs: 5         # PPO n_epochs parameter
    gamma: 0.99         # PPO gamma parameter
    gae_lambda: 0.95    # PPO gae_lambda parameter
    clip_range: 0.3     # PPO clip_range parameter
    additional_log_std_noise: 0.0
    policy_type: "CnnPolicy" # Policy type, e.g., "CnnPolicy" for image-based envs

# --- Model Loading Configuration ---
model_loading:
  dir: "trained_models/"
  load_path: "" # empty string means don't load, otherwise it's a path relative to model_loading.dir
  model_type_to_load: "" # options: "std_enc_dec", "jepa", "enc_dec_jepa_style"

# --- General Training Configuration ---
training:
  num_epochs: 20
  batch_size: 32
  learning_rate: 0.0003 # General learning rate, reduced for stability
  num_workers: 0 # For DataLoader
  log_interval: 20 # Log training progress every N batches
  frame_skipping: 0 # Number of frames to skip. Note: If using action_repetition_k in PPO, this should ideally be 0.
  options:
    skip_std_enc_dec_training_if_loaded: false
    skip_jepa_training_if_loaded: false
  early_stopping: # General early stopping settings; specific metrics/paths are per model type if needed
    patience: 3
    delta: 0.001
    # Metric for Encoder/Decoder, e.g., "val_loss_enc_dec" or "val_accuracy_enc_dec"
    metric_enc_dec: "val_loss_enc_dec"
    checkpoint_path_enc_dec: "best_encoder_decoder.pth" # Relative to model_loading.dir
    # Metric for JEPA, e.g., "val_total_loss_jepa"
    metric_jepa: "val_total_loss_jepa"
    checkpoint_path_jepa: "best_jepa.pth" # Relative to model_loading.dir

# --- Models Configuration ---
models:
  shared_latent_dim: 64 # Output dimension of encoders, input to predictors/decoders
  shared_patch_size: 4   # Global patch_size: Used by ViT encoder, default for decoder_patch_size

  encoder:
    type: "vit"  # Options: "vit", "cnn", "mlp"
    # Specific parameters for the chosen encoder_type.
    # train.py will select the appropriate sub-dictionary based on 'encoder.type'.
    params:
      vit:
        # patch_size for ViT is handled by train.py using models.shared_patch_size
        depth: 4                # Number of Transformer blocks in ViT
        heads: 4                # Number of attention heads in ViT
        mlp_dim: 512            # Dimension of the MLP within ViT Transformer blocks
        pool: 'cls'             # Type of pooling ('cls' token or 'mean' pooling)
        dropout: 0.3              # Increased dropout rate in ViT for regularization
        emb_dropout: 0.1          # Added embedding dropout for regularization
      cnn:
        num_conv_layers: 3      # Number of convolutional layers
        base_filters: 32        # Number of filters in the first convolutional layer
        kernel_size: 3          # Kernel size for convolutional layers
        stride: 2               # Stride for convolutional layers
        padding: 1              # Padding for convolutional layers
        activation_fn_str: 'relu' # Activation function ('relu' or 'gelu')
        fc_hidden_dim: null     # Dimension of an optional fully connected layer before latent output (null for direct)
        dropout_rate: 0         # Dropout rate for CNN encoder
      mlp:
        num_hidden_layers: 2    # Number of hidden layers in the MLP encoder
        hidden_dim: 256         # Dimension of hidden layers in the MLP encoder
        activation_fn_str: 'relu' # Activation function ('relu' or 'gelu')
        dropout_rate: 0       # Dropout rate for MLP encoder

  standard_encoder_decoder:
    variant: "jepa_style"     # Options: "standard", "jepa_style". jepa_style uses a predictor MLP before the decoder, which makes it comparable ot JEPA
    action_emb_dim: 32      # Dimension for embedding actions
    decoder_dim: 64        # Internal dimension of the Transformer decoder
    decoder_depth: 5      # Number of layers in the Transformer decoder
    decoder_heads: 4        # Number of attention heads in the Transformer decoder
    decoder_mlp_dim: 512    # MLP dimension in the Transformer decoder
    decoder_dropout: 0.2    # Dropout for the decoder
    # If models.shared_patch_size is used, ensure your training script handles the defaulting logic.
    decoder_patch_size: 4   # Patch size for reconstructing output. Defaults to models.shared_patch_size if null/not present.

  jepa:
    learning_rate: 0.0003    # Specific learning rate for JEPA optimizer, reduced for stability
    # predictor_output_dim for JEPA model is models.shared_latent_dim
    predictor_hidden_dims: [256, 256] # Hidden dimension for the JEPA predictor MLP. Also used by enc_dec_jepa_style.
    predictor_dropout_rate: 0  # Dropout rate for JEPA predictor MLP layers. Also used by enc_dec_jepa_style.
    ema_decay: 0.99              # EMA decay rate for updating the target encoder in JEPA
    target_encoder_mode: "vjepa2" # Options: "default", "vjepa2", "none"
    # For VICRegLoss coefficients used in JEPA's regularization terms (if not using full auxiliary_loss block for this)
    # vicreg_sim_coeff: 25.0 # (Example, often 0 for JEPA's reg_terms use)
    # vicreg_std_coeff: 25.0
    # vicreg_cov_coeff: 1.0
    decoder_training: # Configuration for training a standalone JEPA State Decoder (not its architecture for embedding)
      enabled: true # Set to true to enable training this decoder
      num_epochs: 20
      learning_rate: 0.0003
      checkpoint_path: "best_jepa_decoder.pth" # Relative to model_loading.dir
      validation_plot_dir: "validation_plots/"
      early_stopping:
        patience: 5
        delta: 0.001
        metric: "val_loss_jepa_decoder" # Example metric

  reward_predictors:
    reward_mlp:
      enabled: true
      input_type: "flatten" # Assumes flattened decoded image from StandardEncoderDecoder
      hidden_dims: [512, 512, 512]
      num_epochs: 20
      activation: "relu"
      use_batch_norm: false
      learning_rate: 0.0003
      log_interval: 100
      dropout_rate: 0.2
      early_stopping_patience: 3
    
    larp: # Look-Ahead Reward Predictor configuration
      enabled: true
      hidden_dims: [512, 512, 512]
      num_epochs: 20
      activation: "relu"
      use_batch_norm: false
      learning_rate: 0.0003
      log_interval: 100
      dropout_rate: 0.2
      early_stopping_patience: 3

  auxiliary_loss: # Configuration for auxiliary losses like VICReg, Barlow Twins, DINO
    type: "vicreg"  # Options: "vicreg", "barlow_twins", "dino"
    use_for_jepa: true # Whether to use this auxiliary loss for JEPA training
    use_for_enc_dec: true # Whether to use this auxiliary loss for Encoder-Decoder training
    weight: 1     # General weight for the chosen auxiliary loss
    params:
      vicreg:
        # For JEPA's use of calculate_reg_terms, only std_coeff and cov_coeff are relevant.
        sim_coeff: 1.0  # Default to 0 as per current train.py for reg_terms
        std_coeff: 1.0  # Reduced from 25.0 for stability
        cov_coeff: 0.1  # Reduced from 1.0 for stability
        eps: 0.0001     # Default VICRegLoss epsilon
        proj_hidden_dim: 512
        proj_output_dim: 512
      barlow_twins:
        lambda_param: 0.0051
        eps: 0.00001
        scale_loss: 1.0
      dino:
        # out_dim for DINOLoss will be set programmatically from model's latent_dim in train.py
        center_ema_decay: 0.9
        eps: 0.00001


# --- V-JEPA2 World Model Configuration ---
vjepa2_world_model:
  stage1:
    # Masked prediction parameters
    masking_ratio: 0.35
    mask_token_dim: 64
    ema_decay: 0.996
    num_epochs: 20  # Reduced from 100
    learning_rate: 0.0001  # Reduced from 0.0003
    early_stopping_patience: 1  # Reduced from 5
    weight_decay: 0.05  # Increased regularization
    
  stage2:
    # World model parameters
    sequence_length: 8
    teacher_forcing_ratio: 0.8
    rollout_steps: 4
    num_epochs: 100  # Reduced from 50
    learning_rate: 0.0001  # Reduced from 0.0003
    early_stopping_patience: 3  # Added early stopping
    weight_decay: 0.05  # Added regularization

# --- Weights & Biases Logging ---
wandb:
  project: "rl_worlds"
  entity: null # Your W&B entity (username or team name)
  run_name_prefix: "exp"
  enabled: true
