import torch
import torch.nn.functional as F # For F.one_hot
import os # For os.path.exists in early stopping save/load
# import time # Not used in this specific function directly

"""Handles the training loop for the JEPA state decoder model."""

def train_jepa_state_decoder(
    jepa_decoder_model, jepa_model, optimizer_jepa_decoder,
    train_dataloader, val_dataloader, loss_fn, device,
    action_dim, action_type,
    decoder_training_config, # This is jepa_decoder_training_config from the main function
    main_model_dir, # This is model_dir from the main function, for paths
    general_log_interval, # Fallback log interval
    wandb_run, # New argument for wandb
    validation_plotter=None # New argument for shared validation plotting
):
    """
    Handles the training and validation process for the JEPA (Joint Embedding
    Predictive Architecture) State Decoder model.

    This function trains a decoder to reconstruct the next state (s_t_plus_1)
    from embeddings generated by a pre-trained JEPA model. It includes training
    and validation loops, loss computation, optimizer steps, logging with
    Weights & Biases (wandb), and an early stopping mechanism. Validation also
    includes plotting a few sample reconstructions.

    Args:
        jepa_decoder_model (torch.nn.Module): The JEPA state decoder model to be trained.
        jepa_model (torch.nn.Module): The pre-trained JEPA model, used for generating
                                      embeddings. It's set to eval mode.
        optimizer_jepa_decoder (torch.optim.Optimizer): Optimizer for the JEPA decoder.
        train_dataloader (torch.utils.data.DataLoader): DataLoader for the training set.
        val_dataloader (torch.utils.data.DataLoader, optional): DataLoader for the validation set.
        loss_fn (callable): The loss function for training (e.g., MSE).
        device (torch.device): The device (CPU or GPU) for computations.
        action_dim (int): Dimension of the action space.
        action_type (str): Type of action space ('discrete' or 'continuous').
        decoder_training_config (dict): Configuration dictionary containing parameters
                                        like 'num_epochs', 'log_interval',
                                        'early_stopping' (patience, delta),
                                        'checkpoint_path', 'enable_validation_plot',
                                        and 'validation_plot_dir'.
        main_model_dir (str): The main directory where models and plots are saved.
                              Used to construct full checkpoint and plot paths.
        general_log_interval (int): Fallback log interval if not specified in
                                    `decoder_training_config`.
        wandb_run (wandb.sdk.wandb_run.Run, optional): Active Weights & Biases run object.
        validation_plotter (ValidationPlotter, optional): Shared validation plotter for 
                                                          consistent plotting across models.

    Returns:
        str or None: The path to the best saved model checkpoint if early stopping
                     occurred and a model was saved, or if training completed and
                     no validation set was provided (last model saved). Returns None
                     if no checkpoint was saved or found.
    """
    print("\nStarting JEPA State Decoder training...")

    # move model to device
    jepa_decoder_model.to(device)

    # Extract params from decoder_training_config
    num_epochs_decoder = decoder_training_config.get('num_epochs', 50)
    decoder_log_interval = decoder_training_config.get('log_interval', general_log_interval)

    early_stopping_specific_config = decoder_training_config.get('early_stopping', {})
    # Fallback to general patience/delta if not specifically in decoder_training_config.early_stopping
    # This requires access to the general patience/delta, or they should be passed in,
    # or defined within this scope if they are meant to be independent.
    # For now, let's assume patience/delta are in early_stopping_specific_config or have defaults.
    patience_decoder = early_stopping_specific_config.get('patience', 10) # Default if not in specific config
    delta_decoder = early_stopping_specific_config.get('delta', 0.001)   # Default if not in specific config

    decoder_cp_name = decoder_training_config.get('checkpoint_path', 'best_jepa_decoder.pth')
    # Construct full checkpoint path using main_model_dir
    checkpoint_path_decoder = os.path.join(main_model_dir, decoder_cp_name)

    early_stopping_state_decoder = {
        'best_val_loss': float('inf'),
        'epochs_no_improve': 0,
        'early_stop_flag': False,
        'patience': patience_decoder,
        'delta': delta_decoder,
        'checkpoint_path': checkpoint_path_decoder # Full path
    }

    for epoch in range(num_epochs_decoder):
        if early_stopping_state_decoder['early_stop_flag']:
            print(f"JEPA State Decoder early stopping triggered before epoch {epoch+1}. Exiting decoder training loop.")
            break

        if jepa_model: jepa_model.eval() # Main JEPA model provides embeddings
        jepa_decoder_model.train()

        epoch_loss_train = 0
        epoch_loss_mse_reconstruction_train = 0
        epoch_loss_mse_diff_train = 0
        num_batches_train = len(train_dataloader) if train_dataloader else 0

        if num_batches_train == 0:
            print(f"JEPA Decoder Epoch {epoch+1} has no training data. Skipping training phase.")
        else:
            for batch_idx, (s_t, a_t, _, s_t_plus_1) in enumerate(train_dataloader):
                s_t, s_t_plus_1 = s_t.to(device), s_t_plus_1.to(device)
                last_frame_of_next_state = s_t_plus_1[:, -1, :, :]
                last_frame_of_next_state = last_frame_of_next_state.unsqueeze(1).to(device)  # Add channel dimension for grayscale
                if action_type == 'discrete':
                    a_t_processed = a_t.to(device)
                else:
                    a_t_processed = a_t.float().to(device)

                optimizer_jepa_decoder.zero_grad()
                with torch.no_grad():
                    if not jepa_model: # Should be caught by caller, but good to check
                        print("Error: Main JEPA model is None for JEPA decoder training.")
                        early_stopping_state_decoder['early_stop_flag'] = True; break
                    pred_emb, _, _, _ = jepa_model(s_t, a_t_processed, s_t_plus_1)

                jepa_predictor_output = pred_emb.detach()
                reconstructed_s_t_plus_1 = jepa_decoder_model(jepa_predictor_output)

                loss_mse_reconstruction = loss_fn(reconstructed_s_t_plus_1, last_frame_of_next_state)

                # Total loss
                loss = loss_mse_reconstruction
                loss.backward()
                optimizer_jepa_decoder.step()
                epoch_loss_train += loss.item()
                epoch_loss_mse_reconstruction_train += loss_mse_reconstruction.item()

                if (batch_idx + 1) % decoder_log_interval == 0:
                    if wandb_run:
                        log_data_decoder_batch = {
                            "JEPA_Decoder/train/total_loss": loss.item(),
                            "JEPA_Decoder/train/loss_mse_reconstruction": loss_mse_reconstruction.item(),
                            "JEPA_Decoder/train/Learning_Rate": optimizer_jepa_decoder.param_groups[0]['lr']
                        }
                        # step current_decoder_global_step aligns with "JEPA_Decoder/train/step"
                        wandb_run.log(log_data_decoder_batch)
            if early_stopping_state_decoder['early_stop_flag']: break # From error in batch loop

        avg_train_loss = epoch_loss_train / num_batches_train if num_batches_train > 0 else 0
        avg_train_loss_mse_reconstruction = epoch_loss_mse_reconstruction_train / num_batches_train if num_batches_train > 0 else 0
        avg_train_loss_mse_diff = epoch_loss_mse_diff_train / num_batches_train if num_batches_train > 0 else 0

        if wandb_run:
            wandb_run.log({
                "JEPA_Decoder/train_epoch_avg/total_loss": avg_train_loss, # avg_train_loss is the total loss
                "JEPA_Decoder/train_epoch_avg/loss_mse_reconstruction": avg_train_loss_mse_reconstruction,
            }) # step epoch + 1 aligns with "JEPA_Decoder/epoch"

        # Validation Phase
        if val_dataloader:
            jepa_decoder_model.eval()
            if jepa_model:
                jepa_model.eval()

            # Set random state for consistent validation plotting across models
            if validation_plotter:
                validation_plotter.set_epoch_random_state(epoch)
                # Select random batch and samples for plotting
                plot_batch_data, plot_sample_indices = validation_plotter.select_random_batch_and_samples(
                    val_dataloader, device
                )

            epoch_loss_val = 0
            epoch_loss_mse_reconstruction_val = 0
            epoch_loss_mse_diff_val = 0
            num_batches_val = len(val_dataloader)
            
            # Store predictions for plotting if needed
            with torch.no_grad():
                for val_batch_idx, (s_t_val, a_t_val, _, s_t_plus_1_val) in enumerate(val_dataloader):
                    s_t_val, s_t_plus_1_val = s_t_val.to(device), s_t_plus_1_val.to(device)
                    last_frame_of_next_state_val = s_t_plus_1_val[:, -1, :, :]
                    last_frame_of_next_state_val = last_frame_of_next_state_val.unsqueeze(1).to(device)  # Add channel dimension for grayscale
                    if action_type == 'discrete':      
                        a_t_val_processed = a_t_val.to(device)
                    else:
                        a_t_val_processed = a_t_val.float().to(device)

                    if not jepa_model:
                         print("Error: Main JEPA model is None during JEPA decoder validation.")
                         early_stopping_state_decoder['early_stop_flag'] = True
                         break
                    pred_emb_val, _, _, _ = jepa_model(s_t_val, a_t_val_processed, s_t_plus_1_val)
                    jepa_predictor_output_val = pred_emb_val.detach()
                    reconstructed_s_t_plus_1_val = jepa_decoder_model(jepa_predictor_output_val)

                    loss_mse_reconstruction_val = loss_fn(reconstructed_s_t_plus_1_val, last_frame_of_next_state_val)
                    val_loss = loss_mse_reconstruction_val # This is the total validation loss

                    epoch_loss_val += val_loss.item()
                    epoch_loss_mse_reconstruction_val += loss_mse_reconstruction_val.item()

                    # Check if this is the batch selected for plotting
                    if (plot_batch_data is not None and 
                        torch.equal(s_t_val, plot_batch_data[0]) and
                        torch.equal(s_t_plus_1_val, plot_batch_data[3])):
                        # Store predictions for the selected samples
                        plot_predictions = reconstructed_s_t_plus_1_val[plot_sample_indices]

                # Handle plotting after validation loop
                if validation_plotter and plot_batch_data is not None and plot_predictions is not None:
                    validation_plotter.plot_validation_samples(
                        batch_data=plot_batch_data,
                        selected_indices=plot_sample_indices,
                        predictions=plot_predictions,
                        epoch=epoch + 1,
                        model_name="JEPA Decoder"
                    )
                if early_stopping_state_decoder['early_stop_flag']: break

                avg_val_loss = epoch_loss_val / num_batches_val if num_batches_val > 0 else float('inf')
                avg_val_loss_mse_reconstruction = epoch_loss_mse_reconstruction_val / num_batches_val if num_batches_val > 0 else float('inf')
                avg_val_loss_mse_diff = epoch_loss_mse_diff_val / num_batches_val if num_batches_val > 0 else float('inf')
                print(f"  Epoch {epoch+1}/{num_epochs_decoder:<5} | "
                      f"{'Avg Train Total Loss':<22}: {avg_train_loss:>8.4f} "
                      f"{'Avg Val Total Loss':<20}: {avg_val_loss:>8.4f} ")
                if wandb_run:
                    wandb_run.log({
                        "JEPA_Decoder/val/total_loss": avg_val_loss,
                        "JEPA_Decoder/val/loss_mse_reconstruction": avg_val_loss_mse_reconstruction,
                    }) # step epoch + 1 aligns with "JEPA_Decoder/epoch"

                if avg_val_loss < early_stopping_state_decoder['best_val_loss'] - early_stopping_state_decoder['delta']:
                    early_stopping_state_decoder['best_val_loss'] = avg_val_loss
                    if early_stopping_state_decoder['checkpoint_path']:
                        os.makedirs(os.path.dirname(early_stopping_state_decoder['checkpoint_path']), exist_ok=True)
                        torch.save(jepa_decoder_model.state_dict(), early_stopping_state_decoder['checkpoint_path'])
                    early_stopping_state_decoder['epochs_no_improve'] = 0
                    print(f"  JEPA Decoder: Val loss improved. Saved model to {early_stopping_state_decoder['checkpoint_path']}")
                else:
                    early_stopping_state_decoder['epochs_no_improve'] += 1
                    print(f"  JEPA Decoder: No val improvement for {early_stopping_state_decoder['epochs_no_improve']} epochs.")
                    if early_stopping_state_decoder['epochs_no_improve'] >= early_stopping_state_decoder['patience']:
                        early_stopping_state_decoder['early_stop_flag'] = True
                        print("  JEPA Decoder: Early stopping triggered.")
        else: # No validation dataloader
            print(f" JEPA Decoder Epoch {epoch+1} Training Summary (No Validation)")
            print(f"  Avg Train Total Loss: {avg_train_loss:>8.4f} (Recon: {avg_train_loss_mse_reconstruction:>8.4f}, Diff: {avg_train_loss_mse_diff:>8.4f})")
            if early_stopping_state_decoder['checkpoint_path']: # Save last epoch if no validation
                os.makedirs(os.path.dirname(early_stopping_state_decoder['checkpoint_path']), exist_ok=True)
                torch.save(jepa_decoder_model.state_dict(), early_stopping_state_decoder['checkpoint_path'])
                print(f"  JEPA Decoder: Saved model from last epoch to {early_stopping_state_decoder['checkpoint_path']} (no validation set)")

        if early_stopping_state_decoder['early_stop_flag']: break

    print("JEPA State Decoder training finished.")

    # Load the best model if it was saved
    best_checkpoint_file = early_stopping_state_decoder['checkpoint_path']
    if best_checkpoint_file and os.path.exists(best_checkpoint_file):
        print(f"Loading best JEPA State Decoder model from {best_checkpoint_file}")
        jepa_decoder_model.load_state_dict(torch.load(best_checkpoint_file, map_location=device))
        return best_checkpoint_file
    elif best_checkpoint_file: # Path was set, but no file (e.g. no training/val epochs ran or never improved)
         print(f"JEPA State Decoder checkpoint {best_checkpoint_file} not found. Using model state as is.")
         return None
    return None
